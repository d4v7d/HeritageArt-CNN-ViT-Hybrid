# POC-5.8: Standard Segmentation Pipeline# POC-5.8: Standard Segmentation Pipeline (Server-Optimized)



## ðŸŽ¯ Objetivo## Objetivo



Implementar pipeline de segmentaciÃ³n **estÃ¡ndar y robusto** usando librerÃ­as probadas industrialmente, tras mÃºltiples fallos con cÃ³digo custom (POC5.5-5.7).Validar que el servidor V100 puede correr segmentaciÃ³n semÃ¡ntica **correctamente** usando arquitecturas y tÃ©cnicas estÃ¡ndar probadas. Abandonar custom implementations problemÃ¡ticas y usar **best practices** de la industria.



## ðŸ“Š Resultados---



### Test 1 Ã‰poca (Job 2060)## FilosofÃ­a: Keep It Simple, Stupid (KISS)

- **Throughput**: 97.0 imgs/s (3.7x mejora vs baseline 26 imgs/s)

- **Tiempo/Ã©poca**: 12.1s (train) + 3.0s (val) = 15.1s totalPOC5.7 fracasÃ³ porque:

- **RAM usage**: 32.8 GB (27GB train + 5.8GB val)- âŒ UPerNet custom con 3 heads â†’ 30GB activations intermedias

- **VRAM usage**: 1.3% (0.41 GB / 31.75 GB)- âŒ Sin mixed precision â†’ 2x VRAM desperdiciada

- **mIoU**: 0.0588 (6% - normal en 1 Ã©poca)- âŒ Arquitectura compleja para 418 imÃ¡genes â†’ overkill

- âŒ Debugging infinito de cÃ³digo custom

### Comparativa POC5.5 (Laptop Baseline)

| MÃ©trica | POC5.5 Laptop | POC5.8 Server | Mejora |POC5.8 soluciÃ³n:

|---------|--------------|---------------|---------|- âœ… Usar `segmentation-models-pytorch` (SMP) - librerÃ­a estÃ¡ndar, probada

| Arquitectura | Custom UPerNet | DeepLabV3+ (SMP) | âœ… Standard |- âœ… Mixed Precision (AMP) desde dÃ­a 1 â†’ 50% menos VRAM

| Throughput | 4 imgs/s | 97 imgs/s | **24x** |- âœ… Arquitectura simple primero (U-Net) â†’ complejidad incremental

| mIoU (final) | 22% | TBD (50 epochs) | - |- âœ… CÃ³digo mÃ­nimo, mÃ¡ximo aprovechamiento de librerÃ­a

| Dataset | 334 images | 1,464 images | **4.4x** |

---

## ðŸ”§ Stack TecnolÃ³gico

## Arquitectura

### Core Libraries

- **PyTorch**: 2.0.1+cu118### Fase 1: Baseline U-Net (30 min - ESTA FASE)

- **SMP**: segmentation-models-pytorch 0.3.3

- **Albumentations**: Data augmentation```

- **AMP**: Automatic Mixed Precision (torch.cuda.amp)Input (3, 384, 384)

    â†“

### ArquitecturaEncoder: ConvNeXt-Tiny (pretrained)

- **Model**: DeepLabV3Plus (ASPP decoder, memory efficient)    â”œâ”€ Stage 1: 96 channels

- **Encoder**: ResNet50 (26.7M params, ImageNet pretrained)    â”œâ”€ Stage 2: 192 channels

- **Loss**: DiceLoss multiclass    â”œâ”€ Stage 3: 384 channels

- **Optimizer**: AdamW + OneCycleLR    â””â”€ Stage 4: 768 channels (bottleneck)

- **Batch size**: 64 (26.7M params Ã— 64 = ~1.7GB activations)    â†“

Decoder: U-Net Skip Connections

### Dataset    â”œâ”€ Up 1: 768 â†’ 384 (+ skip)

- **Original**: ARTeFACT 418 images, 16 damage classes    â”œâ”€ Up 2: 384 â†’ 192 (+ skip)

- **Augmented**: 1,464 images (3x offline multiplier)    â”œâ”€ Up 3: 192 â†’ 96 (+ skip)

- **Augmentations**: HFlip, VFlip, Rotate90/180/270    â””â”€ Up 4: 96 â†’ 16 (final)

- **Split**: 80/20 train/val (1,171 / 293)    â†“

Output: (16, 384, 384) - Fine classes

### InnovaciÃ³n: RAM Pre-loading```

- **Problema**: 80% tiempo en CPU I/O (decode PNG + augmentations)

- **SoluciÃ³n**: Pre-cargar TODAS las imÃ¡genes en RAM al inicio**EstimaciÃ³n:**

- **ImplementaciÃ³n**: `PreloadedArtefactDataset` en `src/preload_dataset.py`- ParÃ¡metros: ~30M

- **Resultado**: I/O â†’ 0%, throughput Ã— 3.7- VRAM con batch=128 + AMP: 12-15GB (40-50%)

- Throughput esperado: >100 imgs/s

## ðŸ“ Estructura

### Fase 2: Hierarchical (OPCIONAL - si Fase 1 funciona)

```

artefact-poc58-standard/```

â”œâ”€â”€ README.md                    # Este archivoShared Encoder (ConvNeXt-Tiny)

â”œâ”€â”€ configs/    â†“

â”‚   â””â”€â”€ unet_convnext_batch128.yaml  # Config principal (DeepLabV3+, batch=64)U-Net Decoder â†’ Fine (16 classes)

â”œâ”€â”€ data/    â”œâ”€ Conv1x1 â†’ Binary (2 classes)

â”‚   â”œâ”€â”€ artefact/                # Dataset original (418 images)    â””â”€ Conv1x1 â†’ Coarse (4 classes)

â”‚   â””â”€â”€ artefact_augmented/      # Dataset augmentado (1,464 images)```

â”œâ”€â”€ logs/

â”‚   â”œâ”€â”€ train_2060.out          # Test exitoso 1 Ã©pocaLightweight heads â†’ solo +2-3GB VRAM vs +20GB en UPerNet

â”‚   â””â”€â”€ old_tests/              # Tests fallidos archivados

â”œâ”€â”€ scripts/---

â”‚   â””â”€â”€ slurm_train.sh          # SLURM job script

â””â”€â”€ src/## Stack TecnolÃ³gico

    â”œâ”€â”€ train.py                # Script principal de training

    â”œâ”€â”€ dataset.py              # Dataset estÃ¡ndar (CPU I/O)### Core Dependencies

    â”œâ”€â”€ preload_dataset.py      # Dataset con RAM pre-loading âš¡

    â””â”€â”€ dali_dataset.py.bak     # DALI fallido (backup)```bash

```# LibrerÃ­a estÃ¡ndar para segmentaciÃ³n

segmentation-models-pytorch==0.3.3

## ðŸš€ Uso

# Ya instaladas

### Test 1 Ã‰pocatorch==2.0.1+cu118

```bashalbumentations

cd /opt/home/btrigueros/HeritageArt-CNN-ViT-Hybrid/experiments/artefact-poc58-standardtimm

sbatch scripts/slurm_train.sh --test-epoch```

```

### Herramientas Clave

### Training Completo (50 Ã‰pocas)

```bash1. **SMP (Segmentation Models PyTorch)**

sbatch scripts/slurm_train.sh   - 500+ combinaciones encoder-decoder pre-configuradas

```   - Encoders: ResNet, EfficientNet, ConvNeXt, Swin, etc.

   - Decoders: U-Net, U-Net++, DeepLabV3+, FPN, etc.

### ConfiguraciÃ³n

2. **PyTorch AMP (Automatic Mixed Precision)**

Editar `configs/unet_convnext_batch128.yaml`:   - FP16 automÃ¡tico en operaciones seguras

   - FP32 en operaciones sensibles (loss, normalizaciÃ³n)

```yaml   - 50% menos VRAM, 2-3x mÃ¡s rÃ¡pido

# Activar/desactivar RAM pre-loading

data:3. **OneCycleLR Scheduler**

  use_preload: true              # RAM pre-loading (97 imgs/s)   - Better que CosineAnnealing para datasets pequeÃ±os

  use_augmented: true            # Dataset augmentado (1,464 imgs)   - Learning rate warmup automÃ¡tico

  

training:---

  batch_size: 64                 # MÃ¡ximo sin OOM

  epochs: 50## Pipeline de Entrenamiento

  mixed_precision: true          # AMP enabled

```### Data



## ðŸ“ˆ MÃ©tricas de Entrenamiento```python

# Augmentations mÃ­nimas (rÃ¡pidas)

El script reporta cada Ã©poca:train_transform = A.Compose([

- **Loss**: DiceLoss train/val    A.Resize(384, 384),

- **mIoU**: Mean IoU across 16 classes    A.HorizontalFlip(p=0.5),

- **Throughput**: imgs/s    A.VerticalFlip(p=0.3),

- **VRAM**: % utilizaciÃ³n GPU    A.RandomRotate90(p=0.3),

- **Time**: Tiempo por Ã©poca    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),

    ToTensorV2()

## ðŸ” Troubleshooting])



### OOM (Out of Memory)# DataLoader optimizado

- Reducir `batch_size` de 64 â†’ 32DataLoader(

- Problema: batch=128 requiere ~28.5GB (OOM en V100 32GB)    dataset,

    batch_size=128,      # Grande con AMP

### Bajo throughput    num_workers=8,       # Max CPUs

- Verificar `use_preload: true` en config    pin_memory=True,     # GPU transfer rÃ¡pido

- Sin pre-loading: ~26 imgs/s (80% I/O wait)    persistent_workers=True,

- Con pre-loading: ~97 imgs/s (I/O eliminado)    prefetch_factor=4    # Prefetch 4 batches

)

### Dataset incompleto```

- Verificar que existan 1,464 images y 1,464 annotations en `artefact_augmented/`

- Si falta alguna: genera con augmentation script### Training Loop con AMP



## ðŸ§ª Experimentos Previos```python

from torch.cuda.amp import autocast, GradScaler

### POC5.5 (Laptop)

- âœ… FuncionÃ³: 22% mIoU, 4 imgs/sscaler = GradScaler()

- âŒ Problema: CÃ³digo custom, lento

for images, masks in train_loader:

### POC5.6 (Server Port)    # Forward en FP16

- âŒ FallÃ³: 1.8% VRAM, GPU underutilization    with autocast():

        predictions = model(images)

### POC5.7 (Server Native)        loss = criterion(predictions, masks)

- âŒ FallÃ³: OOM batchâ‰¥128, 1.9% VRAM batch=64    

    # Backward con gradient scaling

### POC5.8 (Standard Pipeline) â† ACTUAL    scaler.scale(loss).backward()

- âœ… FuncionÃ³: SMP + AMP + RAM pre-loading    scaler.step(optimizer)

- Esperando: mIoU en 50 Ã©pocas    scaler.update()

    optimizer.zero_grad()

## ðŸ“ Notas TÃ©cnicas```



### Â¿Por quÃ© DeepLabV3+ vs U-Net?### Loss Function

- ASPP decoder mÃ¡s eficiente en memoria

- Mejor mIoU (0.0794 vs 0.0494 en 1 Ã©poca)```python

- 21% menos parÃ¡metros (26.7M vs 34.4M)# SMP tiene losses optimizadas

from segmentation_models_pytorch.losses import DiceLoss, FocalLoss

### Â¿Por quÃ© ResNet50 vs ResNeSt50?

- Soporta dilated convolutions (mejor para segmentaciÃ³n)# Fase 1: Single task

- MÃ¡s estÃ¡ndar, mejor documentadocriterion = DiceLoss(mode='multiclass')

- Similar performance, menor complejidad

# Fase 2: Multi-task (si se implementa)

### Â¿Por quÃ© RAM pre-loading?criterion_binary = DiceLoss(mode='binary')

- V100 procesamiento: ~0.5s/batchcriterion_coarse = DiceLoss(mode='multiclass')

- CPU I/O (PNG decode): ~1.9s/batchcriterion_fine = DiceLoss(mode='multiclass')

- **Bottleneck identificado**: 80% tiempo en I/O

- **SoluciÃ³n**: Cargar todo en RAM (32GB disponibles)total_loss = 0.2*L_binary + 0.3*L_coarse + 0.5*L_fine

- **Resultado**: I/O â†’ 0s, throughput Ã— 3.7```



### Â¿Por quÃ© no DALI?### Optimizer & Scheduler

- Intentado: 10+ iteraciones, todos fallaron

- Problema: ExternalSource decode muy complejo para PNGs custom```python

- DecisiÃ³n: RAM pre-loading mÃ¡s simple y efectivo# AdamW con weight decay

optimizer = torch.optim.AdamW(

## ðŸŽ¯ PrÃ³ximos Pasos    model.parameters(),

    lr=1e-3,          # Higher initial LR (OneCycle bajarÃ¡)

1. âœ… Test 1 Ã©poca exitoso (Job 2060)    weight_decay=0.01

2. ðŸ”œ Training 50 Ã©pocas)

3. ðŸ”œ Evaluar mIoU final vs POC5.5 (target: â‰¥22%)

4. ðŸ”œ Si funciona: base para POC6 (ViT integration)# OneCycleLR (mejor que Cosine para pocos datos)

scheduler = torch.optim.lr_scheduler.OneCycleLR(

## ðŸ’¾ Recursos    optimizer,

    max_lr=1e-3,

- **GPU**: Tesla V100S-PCIE-32GB    total_steps=len(train_loader) * epochs,

- **RAM**: 32-48GB (necesita ~33GB para pre-loading)    pct_start=0.3,    # 30% warmup

- **CPUs**: 8-10 cores    anneal_strategy='cos'

- **Tiempo estimado (50 epochs)**: ~12-15 minutos)

```

---

---

**Autor**: POC5.8 Standard Pipeline  

**Fecha**: Noviembre 2025  ## MÃ©tricas Objetivo

**Status**: âœ… Test exitoso, listo para training completo

### GPU Utilization
- âœ… VRAM: **40-60%** (12-18GB de 32GB)
- âœ… Throughput: **>100 imgs/s** (vs POC5.7: 23.9 imgs/s)
- âœ… Time/epoch: **<10s** (vs POC5.7: 17.4s)

### Model Performance
- ðŸŽ¯ Target mIoU (fine): **>25%** en 50 Ã©pocas
  - Baseline POC5.5 laptop: 22% mIoU
  - Con servidor + AMP + mejor arquitectura: debe superar

### Training Time
- ðŸ“Š 1 Ã©poca: <10s
- ðŸ“Š 50 Ã©pocas: <10 min
- ðŸ“Š Total (con validaciÃ³n): <15 min

**ComparaciÃ³n:**
- POC5.5 laptop: ~4 horas
- POC5.8 servidor: ~15 min
- **Speedup: 16x** ðŸš€

---

## Estructura del Proyecto

```
artefact-poc58-standard/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ unet_convnext_batch128.yaml
â”‚   â”œâ”€â”€ unet_swin_batch128.yaml
â”‚   â””â”€â”€ unet_maxvit_batch128.yaml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py              # ARTeFACT dataset loader
â”‚   â”œâ”€â”€ model.py                # SMP model wrapper
â”‚   â”œâ”€â”€ train.py                # Training script con AMP
â”‚   â””â”€â”€ evaluate.py             # Evaluation script
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ slurm_train.sh          # SLURM script (1 GPU)
â”‚   â””â”€â”€ slurm_compare.sh        # Train 3 encoders en paralelo
â””â”€â”€ logs/
    â””â”€â”€ (training logs)
```

---

## Plan de EjecuciÃ³n

### Step 1: Setup (5 min)
```bash
cd artefact-poc58-standard
pip install segmentation-models-pytorch==0.3.3
ln -s ../artefact-poc55-multiclass/data data
```

### Step 2: Test 1 Epoch (5 min)
```bash
sbatch scripts/slurm_train.sh --test-epoch
# Validar: VRAM >40%, throughput >100 imgs/s
```

### Step 3: Full Training (15 min)
```bash
sbatch scripts/slurm_train.sh
# 50 Ã©pocas ConvNeXt-Tiny
```

### Step 4: Multi-Encoder Comparison (30 min)
```bash
sbatch scripts/slurm_compare.sh
# Train ConvNeXt, Swin, MaxViT en paralelo (3 GPUs)
# Compare mIoU
```

---

## Decisiones de DiseÃ±o

### Â¿Por quÃ© U-Net y no UPerNet?

| CaracterÃ­stica | U-Net | UPerNet (POC5.7) |
|----------------|-------|------------------|
| ParÃ¡metros | ~30M | ~38M |
| VRAM @ batch=128 | 12-15GB | 30GB+ (OOM) |
| Throughput | >100 imgs/s | 23.9 imgs/s |
| Complejidad | Baja | Alta |
| Debugging | MÃ­nimo | DÃ­as |

**Veredicto:** U-Net es 90% tan bueno con 1/10 del dolor de cabeza.

### Â¿Por quÃ© Mixed Precision?

- V100 tiene Tensor Cores optimizados para FP16
- FP16 = 2x menos VRAM, 2-3x mÃ¡s rÃ¡pido
- PÃ©rdida numÃ©rica negligible (<0.1% mIoU)
- **No hay razÃ³n para NO usarlo** en 2025

### Â¿Por quÃ© SMP y no custom?

- 200k+ usuarios, battle-tested
- Optimizado para V100/A100
- DocumentaciÃ³n extensa
- Debugging = issue en GitHub, no dÃ­as perdidos

---

## Contingencias

### Si batch=128 da OOM (poco probable):
1. Reducir a batch=96
2. Reducir image_size a 320px
3. Usar gradient accumulation

### Si mIoU <20%:
1. Aumentar augmentations (ColorJitter, etc.)
2. Aumentar Ã©pocas a 100
3. Probar DeepLabV3+ en vez de U-Net

### Si throughput <100 imgs/s:
1. Verificar num_workers=8
2. Verificar persistent_workers=True
3. Verificar AMP habilitado

---

## Ã‰xito Definido

POC5.8 es **exitoso** si en <2 horas:

1. âœ… 1 Ã©poca corre sin errores
2. âœ… VRAM >40% y throughput >100 imgs/s
3. âœ… 50 Ã©pocas completan en <15 min
4. âœ… mIoU â‰¥ 22% (POC5.5 baseline)

Si esto falla, **el problema NO es el cÃ³digo**, es el servidor o PyTorch installation.

---

## PrÃ³ximos Pasos (POC6)

Una vez POC5.8 valida que el servidor funciona:

**POC6 puede agregar innovations SOBRE arquitectura probada:**
- MAE pretraining (sobre U-Net)
- MAML meta-learning (sobre U-Net)
- Domain adaptation (sobre U-Net)
- Attention mechanisms (sobre U-Net)

**No reinventar la rueda de segmentaciÃ³n bÃ¡sica.**

---

## Referencias

- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)
- [PyTorch AMP Tutorial](https://pytorch.org/docs/stable/amp.html)
- [U-Net Paper](https://arxiv.org/abs/1505.04597)
- [OneCycleLR Paper](https://arxiv.org/abs/1708.07120)

---

**FilosofÃ­a final:** "Make it work, make it right, make it fast" - en ese orden. POC5.7 tratÃ³ de hacer todo a la vez. POC5.8 hace una cosa bien.
