# ARTeFACT End-to-End Pipeline

Este pipeline completo te permite entrenar y evaluar tres modelos (CNN, ViT, HÃ­brido) en el dataset ARTeFACT de forma automatizada.

## ğŸ¯ Lo que hace el pipeline

1. **Descarga ARTeFACT**: Descarga el dataset una sola vez y lo guarda localmente
2. **Entrena 3 modelos**:
   - **CNN**: ConvNeXt-Tiny + FPN
   - **ViT**: Swin-Base + UPerNet
   - **HÃ­brido**: MaxViT-Tiny + FPN
3. **EvalÃºa cada modelo**: Calcula mÃ©tricas F1 y mIoU
4. **Genera visualizaciones**: Por cada imagen evaluada, crea:
   - MÃ¡scara de segmentaciÃ³n predicha
   - Ground truth
   - Overlay sobre la imagen original
   - VisualizaciÃ³n comparativa (4 paneles)
   - Archivo JSON con mÃ©tricas F1 y mIoU

## ğŸ“ Estructura de salida

```
logs/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ artefact_real/          # Dataset descargado (se mantiene entre ejecuciones)
â”‚       â”œâ”€â”€ image/
â”‚       â”œâ”€â”€ annotation/
â”‚       â””â”€â”€ metadata.csv
â””â”€â”€ pipeline_results/
    â”œâ”€â”€ checkpoints/             # Modelos entrenados
    â”‚   â”œâ”€â”€ convnext_tiny_fpn_artefact.pth
    â”‚   â”œâ”€â”€ upernet_swin_base_artefact.pth
    â”‚   â””â”€â”€ maxvit_tiny_fpn_artefact.pth
    â”œâ”€â”€ convnext_tiny_fpn/      # Resultados del modelo CNN
    â”‚   â”œâ”€â”€ {image_id}_visualization.png  # 4 paneles comparativos
    â”‚   â”œâ”€â”€ {image_id}_pred.png          # PredicciÃ³n coloreada
    â”‚   â”œâ”€â”€ {image_id}_gt.png            # Ground truth coloreado
    â”‚   â”œâ”€â”€ {image_id}_overlay.png       # Overlay
    â”‚   â”œâ”€â”€ {image_id}_metrics.json      # MÃ©tricas por imagen
    â”‚   â””â”€â”€ overall_metrics.json         # MÃ©tricas generales del modelo
    â”œâ”€â”€ upernet_swin_base/      # Resultados del modelo ViT
    â”‚   â””â”€â”€ ... (mismo formato)
    â”œâ”€â”€ maxvit_tiny_fpn/        # Resultados del modelo HÃ­brido
    â”‚   â””â”€â”€ ... (mismo formato)
    â””â”€â”€ summary_results.json    # ComparaciÃ³n de los 3 modelos
```

## ğŸš€ Uso

### OpciÃ³n 1: Pipeline rÃ¡pido (recomendado para pruebas)
```bash
make build              # Solo la primera vez
make pipeline-quick     # 30 muestras, 10 epochs, 10 imÃ¡genes de evaluaciÃ³n
```

### OpciÃ³n 2: Pipeline personalizado
```bash
make build  # Solo la primera vez
make pipeline MAX_SAMPLES=100 EPOCHS=20 MAX_EVAL=20
```

ParÃ¡metros:
- `MAX_SAMPLES`: Cantidad de muestras a descargar de ARTeFACT (None = todas, ~400)
- `EPOCHS`: NÃºmero de epochs para entrenar cada modelo
- `MAX_EVAL`: MÃ¡ximo de imÃ¡genes para evaluar y visualizar

### OpciÃ³n 3: Solo evaluaciÃ³n (usa checkpoints existentes)
```bash
make pipeline-eval-only  # Salta el entrenamiento, usa modelos ya entrenados
```

## â±ï¸ Tiempos estimados

Con GPU NVIDIA (ejemplo RTX 3090):
- **Pipeline rÃ¡pido**: ~30-45 minutos
  - Descarga: ~5 min (30 muestras)
  - Entrenamiento: ~5-8 min por modelo (10 epochs)
  - EvaluaciÃ³n: ~2 min por modelo (10 imÃ¡genes)

- **Pipeline completo** (100 muestras, 20 epochs):
  - Descarga: ~15-20 min
  - Entrenamiento: ~10-15 min por modelo
  - EvaluaciÃ³n: ~4 min por modelo (20 imÃ¡genes)

## ğŸ“Š MÃ©tricas generadas

Para cada imagen evaluada (`{image_id}_metrics.json`):
```json
{
  "image_id": "0001",
  "mIoU": 0.6234,
  "mF1": 0.7123,
  "per_class_iou": [0.89, 0.45, ...],
  "per_class_f1": [0.94, 0.62, ...]
}
```

Resumen general (`overall_metrics.json`):
```json
{
  "model_name": "convnext_tiny_fpn",
  "mean_mIoU": 0.6234,
  "std_mIoU": 0.0523,
  "mean_mF1": 0.7123,
  "std_mF1": 0.0412,
  "num_images": 20
}
```

ComparaciÃ³n de modelos (`summary_results.json`):
- MÃ©tricas de los 3 modelos para comparaciÃ³n directa

## ğŸ” VisualizaciÃ³n de resultados

Cada imagen genera 4 archivos:
1. **`{id}_visualization.png`**: Panel de 2x2 con original, GT, predicciÃ³n y overlay
2. **`{id}_pred.png`**: MÃ¡scara de segmentaciÃ³n predicha (coloreada)
3. **`{id}_gt.png`**: Ground truth (coloreada)
4. **`{id}_overlay.png`**: PredicciÃ³n superpuesta sobre la imagen original

## ğŸ”„ Ejecuciones subsecuentes

El dataset ARTeFACT se descarga **una sola vez** y se guarda en `logs/data/artefact_real/`. En ejecuciones posteriores:
- Si el directorio existe, **no se descarga de nuevo**
- Solo se re-entrena y evalÃºa segÃºn los parÃ¡metros especificados

Para forzar una nueva descarga:
```bash
rm -rf logs/data/artefact_real
make pipeline-quick
```

## ğŸ¨ Clases de daÃ±o (16 clases)

0. Clean (limpio)
1. Material loss (pÃ©rdida de material)
2. Peel (desprendimiento)
3. Dust (polvo)
4. Scratch (rayadura)
5. Hair (pelo)
6. Dirt (suciedad)
7. Fold (pliegue)
8. Writing (escritura)
9. Cracks (grietas)
10. Staining (manchas)
11. Stamp (sello)
12. Sticker (adhesivo)
13. Puncture (perforaciÃ³n)
14. Burn marks (marcas de quemadura)
15. Lightleak (fuga de luz)

## ğŸ› Troubleshooting

### Error de memoria compartida (shared memory)
Si ves `Bus error` o `shared memory` error:
- El pipeline ya usa `num_workers=0` para evitar esto
- Si persiste, reduce `--batch-size 2` a `--batch-size 1`

### Descarga muy lenta
- Usa `MAX_SAMPLES=30` o `MAX_SAMPLES=50` para pruebas rÃ¡pidas
- El dataset completo (~400 imÃ¡genes) puede tardar 20-30 min

### GPU sin memoria
- Reduce batch size en el cÃ³digo o usa menos samples
- El pipeline estÃ¡ configurado para batch_size=2 que funciona en GPUs de 8GB

## ğŸ“ Notas

- Los modelos vienen con **pesos pre-entrenados** de ImageNet/similares
- El **fine-tuning** ajusta estos pesos al dataset ARTeFACT
- Los checkpoints se guardan y pueden reutilizarse con `pipeline-eval-only`
